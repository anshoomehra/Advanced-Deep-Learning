{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCNs Fully Convolutional Networks .. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1x1 Conv Quiz**\n",
    "\n",
    "In this quiz you'll learn how to rewrite a dense layer, tf.layers.dense as a convolutional layer, tf.layers.conv2d. The underlying math will be the same, but the spatial information will be preserved allowing seamless use of future convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Output = [[[[ 0.4621644  -2.43662381]\n",
      "   [ 0.01521335 -0.08020782]]\n",
      "\n",
      "  [[-0.52631658  2.77484703]\n",
      "   [ 0.26674098 -1.40631199]]]]\n",
      "Conv 1x1 Output = [[[[ 0.4621644  -2.43662381]\n",
      "   [ 0.01521335 -0.08020782]]\n",
      "\n",
      "  [[-0.52631658  2.77484703]\n",
      "   [ 0.26674098 -1.40631199]]]]\n",
      "Same output? = True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import oldtensorflow as tf\n",
    "\n",
    "\n",
    "# custom init with the seed set to 0 by default\n",
    "def custom_init(shape, dtype=tf.float32, partition_info=None, seed=0):\n",
    "    return tf.random_normal(shape, dtype=dtype, seed=seed)\n",
    "\n",
    "\n",
    "def conv_1x1(x, num_outputs):\n",
    "    kernel_size = 1\n",
    "    stride = 1\n",
    "    return tf.layers.conv2d(x, num_outputs, kernel_size, stride, kernel_initializer=custom_init)#, weights_initializer=custom_init)\n",
    "\n",
    "\n",
    "num_outputs = 2\n",
    "x = tf.constant(np.random.randn(1, 2, 2, 1), dtype=tf.float32)\n",
    "# `tf.layers.dense` flattens the input tensor if the rank > 2 and reshapes it back to the original rank\n",
    "# as the output.\n",
    "dense_out = tf.layers.dense(x, num_outputs, kernel_initializer=custom_init)#, weights_initializer=custom_init)\n",
    "conv_out = conv_1x1(x, num_outputs)\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    a = sess.run(dense_out)\n",
    "    b = sess.run(conv_out)\n",
    "    print(\"Dense Output =\", a)\n",
    "    print(\"Conv 1x1 Output =\", b)\n",
    "\n",
    "    print(\"Same output? =\", np.allclose(a, b, atol=1.e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Transpose Convolution / Decconvolution **\n",
    "\n",
    "Transposed convolutions are used to upsample the input and are a core part of the FCN architecture.\n",
    "\n",
    "In TensorFlow, the API tf.layers.conv2d_transpose is used to create a transposed convolutional layer. Using this documentation, use tf.layers.conv2d_transpose to apply 2x upsampling in the following quiz.\n",
    "\n",
    "One possible answer is using tf.layers.conv2d_transpose(x, 3, (2, 2), (2, 2)) to upsample.\n",
    "\n",
    "The second argument 3 is the number of kernels/output channels.\n",
    "The third argument is the kernel size, (2, 2). Note that the kernel size could also be (1, 1) and the output shape would be the same. However, if it were changed to (3, 3) note the shape would be (9, 9), at least with 'VALID' padding.\n",
    "The fourth argument, the number of strides, is how we get from a height and width from (4, 4) to (8, 8). If this were a regular convolution the output height and width would be (2, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (1, 4, 4, 3)\n",
      "Output Shape: (1, 8, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "#import oldtensorflow as tf\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def upsample(x):\n",
    "    \"\"\"\n",
    "    Apply a two times upsample on x and return the result.\n",
    "    :x: 4-Rank Tensor\n",
    "    :return: TF Operation\n",
    "    \"\"\"\n",
    "    # TODO: Use `tf.layers.conv2d_transpose`\n",
    "    return tf.layers.conv2d_transpose(x, 3, (2, 2), (2, 2))\n",
    "\n",
    "\n",
    "x = tf.constant(np.random.randn(1, 4, 4, 3), dtype=tf.float32)\n",
    "conv = upsample(x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    result = sess.run(conv)\n",
    "\n",
    "    print('Input Shape: {}'.format(x.get_shape()))\n",
    "    print('Output Shape: {}'.format(result.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last Step is Skip Connection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
